{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cb1537e6",
   "metadata": {},
   "source": [
    "# Using Redis as a Vector Database with OpenAI\n",
    "\n",
    "This notebook provides an introduction to using Redis as a vector database with OpenAI embeddings. Redis is a scalable, real-time database that can be used as a vector database when using the [RediSearch Module](https://oss.redislabs.com/redisearch/). The RediSearch module allows you to index and search for vectors in Redis. This notebook will show you how to use the RediSearch module to index and search for vectors created by using the OpenAI API and stored in Redis.\n",
    "\n",
    "### What is Redis?\n",
    "\n",
    "Most developers from a web services background are probably familiar with Redis. At it's core, Redis is an open-source key-value store that can be used as a cache, message broker, and database. Developers choice Redis because it is fast, has a large ecosystem of client libraries, and has been deployed by major enterprises for years.\n",
    "\n",
    "In addition to the traditional uses of Redis. Redis also provides [Redis Modules](https://redis.io/modules) which are a way to extend Redis with new data types and commands. Example modules include [RedisJSON](https://redis.io/docs/stack/json/), [RedisTimeSeries](https://redis.io/docs/stack/timeseries/), [RedisBloom](https://redis.io/docs/stack/bloom/) and [RediSearch](https://redis.io/docs/stack/search/).\n",
    "\n",
    "### What is RediSearch?\n",
    "\n",
    "RediSearch is a [Redis module](https://redis.io/modules) that provides querying, secondary indexing, full-text search and vector search for Redis. To use RediSearch, you first declare indexes on your Redis data. You can then use the RediSearch clients to query that data. For more information on the feature set of RediSearch, see the [README](./README.md) or the [RediSearch documentation](https://redis.io/docs/stack/search/).\n",
    "\n",
    "### Deployment options\n",
    "\n",
    "There are a number of ways to deploy Redis. For local development, the quickest method is to use the [Redis Stack docker container](https://hub.docker.com/r/redis/redis-stack) which we will use here. Redis Stack contains a number of Redis modules that can be used together to create a fast, multi-model data store and query engine.\n",
    "\n",
    "For production use cases, The easiest way to get started is to use the [Redis Cloud](https://redislabs.com/redis-enterprise-cloud/overview/) service. Redis Cloud is a fully managed Redis service. You can also deploy Redis on your own infrastructure using [Redis Enterprise](https://redislabs.com/redis-enterprise/overview/). Redis Enterprise is a fully managed Redis service that can be deployed in kubernetes, on-premises or in the cloud.\n",
    "\n",
    "Additionally, every major cloud provider ([AWS Marketplace](https://aws.amazon.com/marketplace/pp/prodview-e6y7ork67pjwg?sr=0-2&ref_=beagle&applicationId=AWSMPContessa), [Google Marketplace](https://console.cloud.google.com/marketplace/details/redislabs-public/redis-enterprise?pli=1), or [Azure Marketplace](https://azuremarketplace.microsoft.com/en-us/marketplace/apps/garantiadata.redis_enterprise_1sp_public_preview?tab=Overview)) offers Redis Enterprise in a marketplace offering.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f1a618c5",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "Before we start this project, we need to set up the following:\n",
    "\n",
    "* start a Redis database with RediSearch (redis-stack)\n",
    "* install libraries\n",
    "    * [Redis-py](https://github.com/redis/redis-py)\n",
    "\n",
    "===========================================================\n",
    "\n",
    "### Start Redis\n",
    "\n",
    "To keep this example simple, we will use the Redis Stack docker container which we can start as follows\n",
    "\n",
    "```bash\n",
    "$ docker-compose up -d\n",
    "```\n",
    "\n",
    "This also includes the [RedisInsight](https://redis.com/redis-enterprise/redis-insight/) GUI for managing your Redis database which you can view at [http://localhost:8001](http://localhost:8001) once you start the docker container.\n",
    "\n",
    "You're all set up and ready to go! Next, we import and create our client for communicating with the Redis database we just created."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b9babafe",
   "metadata": {},
   "source": [
    "## Install Requirements\n",
    "\n",
    "Redis-Py is the python client for communicating with Redis. We will use this to communicate with our Redis-stack database. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "97fefe4c",
   "metadata": {},
   "source": [
    "## Load data\n",
    "\n",
    "In this section we'll load embedded data that has already been converted into vectors. We'll use this data to create an index in Redis and then search for similar vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9fbebe0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Downloaded\n"
     ]
    },
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[52], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnbutils\u001b[39;00m\n\u001b[1;32m     13\u001b[0m nbutils\u001b[39m.\u001b[39mdownload_wikipedia_data()\n\u001b[0;32m---> 14\u001b[0m data \u001b[39m=\u001b[39m nbutils\u001b[39m.\u001b[39;49mread_wikipedia_data()\n\u001b[1;32m     16\u001b[0m data\u001b[39m.\u001b[39mhead()\n",
      "File \u001b[0;32m~/MyGitHub/openai-cookbook-python/examples/vector_databases/redis/nbutils.py:40\u001b[0m, in \u001b[0;36mread_wikipedia_data\u001b[0;34m(data_path, file_name)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mread_wikipedia_data\u001b[39m(data_path: \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m../../data/\u001b[39m\u001b[39m'\u001b[39m, file_name: \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mvector_database_wikipedia_articles_embedded\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m pd\u001b[39m.\u001b[39mDataFrame:\n\u001b[1;32m     39\u001b[0m     csv_file_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(data_path, file_name \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m.csv\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 40\u001b[0m     data \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(csv_file_path)\n\u001b[1;32m     41\u001b[0m     \u001b[39m# Read vectors from strings back into a list\u001b[39;00m\n\u001b[1;32m     42\u001b[0m     data[\u001b[39m'\u001b[39m\u001b[39mtitle_vector\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mtitle_vector\u001b[39m.\u001b[39mapply(literal_eval)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    899\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    900\u001b[0m     dialect,\n\u001b[1;32m    901\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    908\u001b[0m     dtype_backend\u001b[39m=\u001b[39mdtype_backend,\n\u001b[1;32m    909\u001b[0m )\n\u001b[1;32m    910\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 912\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py:583\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    580\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n\u001b[1;32m    582\u001b[0m \u001b[39mwith\u001b[39;00m parser:\n\u001b[0;32m--> 583\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\u001b[39m.\u001b[39;49mread(nrows)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py:1704\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1697\u001b[0m nrows \u001b[39m=\u001b[39m validate_integer(\u001b[39m\"\u001b[39m\u001b[39mnrows\u001b[39m\u001b[39m\"\u001b[39m, nrows)\n\u001b[1;32m   1698\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1699\u001b[0m     \u001b[39m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[1;32m   1700\u001b[0m     (\n\u001b[1;32m   1701\u001b[0m         index,\n\u001b[1;32m   1702\u001b[0m         columns,\n\u001b[1;32m   1703\u001b[0m         col_dict,\n\u001b[0;32m-> 1704\u001b[0m     ) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mread(  \u001b[39m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[1;32m   1705\u001b[0m         nrows\n\u001b[1;32m   1706\u001b[0m     )\n\u001b[1;32m   1707\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m   1708\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/parsers/c_parser_wrapper.py:234\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    233\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlow_memory:\n\u001b[0;32m--> 234\u001b[0m         chunks \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_reader\u001b[39m.\u001b[39;49mread_low_memory(nrows)\n\u001b[1;32m    235\u001b[0m         \u001b[39m# destructive to chunks\u001b[39;00m\n\u001b[1;32m    236\u001b[0m         data \u001b[39m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/_libs/parsers.pyx:812\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/_libs/parsers.pyx:873\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/_libs/parsers.pyx:848\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/_libs/parsers.pyx:859\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/_libs/parsers.pyx:2025\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import List\n",
    "\n",
    "# use helper function in nbutils.py to download and read the data\n",
    "# this should take from 5-10 min to run\n",
    "if os.getcwd() not in sys.path:\n",
    "    sys.path.append(os.getcwd())\n",
    "import nbutils\n",
    "\n",
    "nbutils.download_wikipedia_data()\n",
    "data = nbutils.read_wikipedia_data()\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "91df4d5b",
   "metadata": {},
   "source": [
    "## Connect to Redis\n",
    "\n",
    "Now that we have our Redis database running, we can connect to it using the Redis-py client. We will use the default host and port for the Redis database which is `localhost:6379`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc662c1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import redis\n",
    "from redis.commands.search.indexDefinition import (\n",
    "    IndexDefinition,\n",
    "    IndexType\n",
    ")\n",
    "from redis.commands.search.query import Query\n",
    "from redis.commands.search.field import (\n",
    "    TextField,\n",
    "    VectorField\n",
    ")\n",
    "\n",
    "REDIS_HOST =  \"localhost\"\n",
    "REDIS_PORT = 6379\n",
    "REDIS_PASSWORD = \"p@$$w0rdw!th0ut\" # default for passwordless Redis\n",
    "\n",
    "# Connect to Redis\n",
    "redis_client = redis.Redis(\n",
    "    host=REDIS_HOST,\n",
    "    port=REDIS_PORT,\n",
    "    password=REDIS_PASSWORD\n",
    ")\n",
    "redis_client.ping()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7d3dac3c",
   "metadata": {},
   "source": [
    "## Creating a Search Index in Redis\n",
    "\n",
    "The below cells will show how to specify and create a search index in Redis. We will:\n",
    "\n",
    "1. Set some constants for defining our index like the distance metric and the index name\n",
    "2. Define the index schema with RediSearch fields\n",
    "3. Create the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f894b911",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Constants\n",
    "VECTOR_DIM = 1536       #len(data['title_vector'][0])    # length of the vectors\n",
    "VECTOR_NUMBER = 25000   #len(data)                 # initial number of vectors\n",
    "INDEX_NAME = \"embeddings-index\"           # name of the search index\n",
    "PREFIX = \"doc\"                            # prefix for the document keys\n",
    "DISTANCE_METRIC = \"COSINE\"                # distance metric for the vectors (ex. COSINE, IP, L2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15db8380",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define RediSearch fields for each of the columns in the dataset\n",
    "title = TextField(name=\"title\")\n",
    "url = TextField(name=\"url\")\n",
    "text = TextField(name=\"text\")\n",
    "title_embedding = VectorField(\"title_vector\",\n",
    "    \"FLAT\", {\n",
    "        \"TYPE\": \"FLOAT32\",\n",
    "        \"DIM\": VECTOR_DIM,\n",
    "        \"DISTANCE_METRIC\": DISTANCE_METRIC,\n",
    "        \"INITIAL_CAP\": VECTOR_NUMBER,\n",
    "    }\n",
    ")\n",
    "text_embedding = VectorField(\"content_vector\",\n",
    "    \"FLAT\", {\n",
    "        \"TYPE\": \"FLOAT32\",\n",
    "        \"DIM\": VECTOR_DIM,\n",
    "        \"DISTANCE_METRIC\": DISTANCE_METRIC,\n",
    "        \"INITIAL_CAP\": VECTOR_NUMBER,\n",
    "    }\n",
    ")\n",
    "fields = [title, url, text, title_embedding, text_embedding]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3658693c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index already exists\n"
     ]
    }
   ],
   "source": [
    "# Check if index exists\n",
    "try:\n",
    "    redis_client.ft(INDEX_NAME).info()\n",
    "    print(\"Index already exists\")\n",
    "except:\n",
    "    # Create RediSearch Index\n",
    "    redis_client.ft(INDEX_NAME).create_index(\n",
    "        fields = fields,\n",
    "        definition = IndexDefinition(prefix=[PREFIX], index_type=IndexType.HASH)\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "775c15b4",
   "metadata": {},
   "source": [
    "## Load Documents into the Index\n",
    "\n",
    "Now that we have a search index, we can load documents into it. We will use the same documents we used in the previous examples. In Redis, either the HASH or JSON (if using RedisJSON in addition to RediSearch) data types can be used to store documents. We will use the HASH data type in this example. The below cells will show how to load documents into the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d791186",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'redis' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mindex_documents\u001b[39m(client: redis\u001b[39m.\u001b[39mRedis, prefix: \u001b[39mstr\u001b[39m, documents: pd\u001b[39m.\u001b[39mDataFrame):\n\u001b[1;32m      4\u001b[0m     records \u001b[39m=\u001b[39m documents\u001b[39m.\u001b[39mto_dict(\u001b[39m\"\u001b[39m\u001b[39mrecords\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m     \u001b[39mfor\u001b[39;00m doc \u001b[39min\u001b[39;00m records:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'redis' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def index_documents(client: redis.Redis, prefix: str, documents: pd.DataFrame):\n",
    "    records = documents.to_dict(\"records\")\n",
    "    for doc in records:\n",
    "        key = f\"{prefix}:{str(doc['id'])}\"\n",
    "\n",
    "        # create byte vectors for title and content\n",
    "        title_embedding = np.array(doc[\"title_vector\"], dtype=np.float32).tobytes()\n",
    "        content_embedding = np.array(doc[\"content_vector\"], dtype=np.float32).tobytes()\n",
    "\n",
    "        # replace list of floats with byte vectors\n",
    "        doc[\"title_vector\"] = title_embedding\n",
    "        doc[\"content_vector\"] = content_embedding\n",
    "\n",
    "        client.hset(key, mapping = doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bfaeafa",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m index_documents(redis_client, PREFIX, data)\n\u001b[1;32m      2\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mLoaded \u001b[39m\u001b[39m{\u001b[39;00mredis_client\u001b[39m.\u001b[39minfo()[\u001b[39m'\u001b[39m\u001b[39mdb0\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mkeys\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m documents in Redis search index with name: \u001b[39m\u001b[39m{\u001b[39;00mINDEX_NAME\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "index_documents(redis_client, PREFIX, data)\n",
    "print(f\"Loaded {redis_client.info()['db0']['keys']} documents in Redis search index with name: {INDEX_NAME}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "46050ca9",
   "metadata": {},
   "source": [
    "## Simple Vector Search Queries with OpenAI Query Embeddings\n",
    "\n",
    "Now that we have a search index and documents loaded into it, we can run search queries. Below we will provide a function that will run a search query and return the results. Using this function we run a few queries that will show how you can utilize Redis as a vector database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b044aa93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import List\n",
    "\n",
    "def search_redis(\n",
    "    redis_client,\n",
    "    user_query,\n",
    "    index_name: str = \"embeddings-index\",\n",
    "    vector_field: str = \"title_vector\",\n",
    "    return_fields: list = [\"title\", \"url\", \"text\", \"vector_score\"],\n",
    "    hybrid_fields = \"*\",\n",
    "    k: int = 20,\n",
    "    print_results: bool = True,\n",
    ") -> List[dict]:\n",
    "\n",
    "    # Creates embedding vector from user query\n",
    "\n",
    "    # embedded_query = openai.Embedding.create(input=user_query,\n",
    "    #                                         model=\"text-embedding-ada-002\",\n",
    "    #                                         )[\"data\"][0]['embedding']\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "    # Prepare the Query\n",
    "    base_query = f'{hybrid_fields}=>[KNN {k} @{vector_field} $vector AS vector_score]'\n",
    "    query = (\n",
    "        Query(base_query)\n",
    "         .return_fields(*return_fields)\n",
    "         .sort_by(\"vector_score\")\n",
    "         .paging(0, k)\n",
    "         .dialect(2)\n",
    "    )\n",
    "    params_dict = {\"vector\": user_query.tobytes()}\n",
    "\n",
    "    # perform vector search\n",
    "    results = redis_client.ft(index_name).search(query, params_dict)\n",
    "    if print_results:\n",
    "        for i, article in enumerate(results.docs):\n",
    "            score = 1 - float(article.vector_score)\n",
    "            print(f\"{i}. {article.title} (Score: {round(score ,3) })\")\n",
    "    return results.docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7e2025f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8998967  0.2107246  0.7702821  ... 0.3043174  0.80106133 0.563753  ]\n",
      "0. 1956 Winter Olympics (Score: 0.014)\n",
      "1. 1964 Winter Olympics (Score: 0.013)\n",
      "2. 1968 Winter Olympics (Score: 0.013)\n",
      "3. 2006 Winter Olympics (Score: 0.013)\n",
      "4. 1956 Summer Olympics (Score: 0.013)\n",
      "5. 1952 Winter Olympics (Score: 0.012)\n",
      "6. 1976 Winter Olympics (Score: 0.012)\n",
      "7. International Olympic Committee (Score: 0.011)\n",
      "8. Columbia Pictures (Score: 0.011)\n",
      "9. 1952 Summer Olympics (Score: 0.011)\n"
     ]
    }
   ],
   "source": [
    "# For using OpenAI to generate query embedding\n",
    "\n",
    "   # 生成随机浮点数数组\n",
    "arr = np.random.rand(VECTOR_DIM).astype(np.float32)\n",
    "\n",
    "results = search_redis(redis_client, arr, k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "93c4a696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.26773906 0.07457433 0.834773   ... 0.6099172  0.42605773 0.36555848]\n",
      "0. Goths (Score: -0.014)\n",
      "1. Athelstan (Score: -0.017)\n",
      "2. Morris Gleitzman (Score: -0.019)\n",
      "3. Fergie (Score: -0.019)\n",
      "4. Evershot (Score: -0.02)\n",
      "5. Goth subculture (Score: -0.02)\n",
      "6. Order of the British Empire (Score: -0.02)\n",
      "7. Hopwood, Worcestershire (Score: -0.021)\n",
      "8. Judas Priest (Score: -0.021)\n",
      "9. Trenton, New Jersey (Score: -0.022)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "arr = np.random.rand(1536).astype(np.float32)\n",
    "\n",
    "    # 打印数组\n",
    "print(arr)\n",
    "results = search_redis(redis_client, arr, vector_field='content_vector', k=10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2007be48",
   "metadata": {},
   "source": [
    "## Hybrid Queries with Redis\n",
    "\n",
    "The previous examples showed how run vector search queries with RediSearch. In this section, we will show how to combine vector search with other RediSearch fields for hybrid search. In the below example, we will combine vector search with full text search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6c25ee8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3343088  0.651979   0.26467764 ... 0.75489277 0.54811966 0.23143286]\n",
      "0. Scottish Gaelic language (Score: -0.028)\n",
      "1. Scottish language (Score: -0.033)\n",
      "2. List of Scottish monarchs (Score: -0.036)\n",
      "3. Scottish Socialist Party (Score: -0.036)\n",
      "4. Second War of Scottish Independence (Score: -0.037)\n"
     ]
    }
   ],
   "source": [
    "arr = np.random.rand(VECTOR_DIM).astype(np.float32)\n",
    "\n",
    "def create_hybrid_field(field_name: str, value: str) -> str:\n",
    "    return f'@{field_name}:\"{value}\"'\n",
    "\n",
    "# search the content vector for articles about famous battles in Scottish history and only include results with Scottish in the title\n",
    "results = search_redis(redis_client,\n",
    "                       arr,\n",
    "                       vector_field=\"title_vector\",\n",
    "                       k=5,\n",
    "                       hybrid_fields=create_hybrid_field(\"title\", \"Scottish\")\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2c0d11d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.40654075 0.98259807 0.4405015  ... 0.74478084 0.4145882  0.7909792 ]\n",
      "0. Public domain (Score: -0.004)\n",
      "1. August 21 (Score: -0.007)\n",
      "2. Po (river) (Score: -0.011)\n",
      "3. Louvre (Score: -0.011)\n",
      "4. August 2 (Score: -0.013)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The opposite of \"public domain\" is copyrighted material, which is owned either by the creator of the work or their estate.  The term public domain is only used to describe things that can be copyrighted, such as photographs, drawings, written articles, books or plays, or similar works of art.  As a general rule, all intellectual property works, after enough time has gone by, will become part of public domain. Examples include the works of Leonardo da Vinci, William Shakespeare and Ludwig van Beethoven, and the books of Isaac Newton.'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = np.random.rand(VECTOR_DIM).astype(np.float32)\n",
    "\n",
    "# run a hybrid query for articles about Art in the title vector and only include results with the phrase \"Leonardo da Vinci\" in the text\n",
    "results = search_redis(redis_client,\n",
    "                       arr,\n",
    "                       vector_field=\"title_vector\",\n",
    "                       k=5,\n",
    "                       hybrid_fields=create_hybrid_field(\"text\", \"Leonardo da Vinci\")\n",
    "                       )\n",
    "\n",
    "# find specific mention of Leonardo da Vinci in the text that our full-text-search query returned\n",
    "mention = [sentence for sentence in results[0].text.split(\"\\n\") if \"Leonardo da Vinci\" in sentence][0]\n",
    "mention"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f8aebbe3",
   "metadata": {},
   "source": [
    "## HNSW Index\n",
    "\n",
    "Up until now, we've been using the ``FLAT`` or \"brute-force\" index to run our queries. Redis also supports the ``HNSW`` index which is a fast, approximate index. The ``HNSW`` index is a graph-based index that uses a hierarchical navigable small world graph to store vectors. The ``HNSW`` index is a good choice for large datasets where you want to run approximate queries.\n",
    "\n",
    "``HNSW`` will take longer to build and consume more memory for most cases than ``FLAT`` but will be faster to run queries on, especially for large datasets.\n",
    "\n",
    "The following cells will show how to create an ``HNSW`` index and run queries with it using the same data as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "865c30f3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'title' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 18\u001b[0m\n\u001b[1;32m      2\u001b[0m title_embedding \u001b[39m=\u001b[39m VectorField(\u001b[39m\"\u001b[39m\u001b[39mtitle_vector\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      3\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mHNSW\u001b[39m\u001b[39m\"\u001b[39m, {\n\u001b[1;32m      4\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mTYPE\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mFLOAT32\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      8\u001b[0m     }\n\u001b[1;32m      9\u001b[0m )\n\u001b[1;32m     10\u001b[0m text_embedding \u001b[39m=\u001b[39m VectorField(\u001b[39m\"\u001b[39m\u001b[39mcontent_vector\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     11\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mHNSW\u001b[39m\u001b[39m\"\u001b[39m, {\n\u001b[1;32m     12\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mTYPE\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mFLOAT32\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     16\u001b[0m     }\n\u001b[1;32m     17\u001b[0m )\n\u001b[0;32m---> 18\u001b[0m fields \u001b[39m=\u001b[39m [title, url, text, title_embedding, text_embedding]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'title' is not defined"
     ]
    }
   ],
   "source": [
    "# re-define RediSearch vector fields to use HNSW index\n",
    "title_embedding = VectorField(\"title_vector\",\n",
    "    \"HNSW\", {\n",
    "        \"TYPE\": \"FLOAT32\",\n",
    "        \"DIM\": VECTOR_DIM,\n",
    "        \"DISTANCE_METRIC\": DISTANCE_METRIC,\n",
    "        \"INITIAL_CAP\": VECTOR_NUMBER\n",
    "    }\n",
    ")\n",
    "text_embedding = VectorField(\"content_vector\",\n",
    "    \"HNSW\", {\n",
    "        \"TYPE\": \"FLOAT32\",\n",
    "        \"DIM\": VECTOR_DIM,\n",
    "        \"DISTANCE_METRIC\": DISTANCE_METRIC,\n",
    "        \"INITIAL_CAP\": VECTOR_NUMBER\n",
    "    }\n",
    ")\n",
    "fields = [title, url, text, title_embedding, text_embedding]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "347e1e70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index already exists\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "# Check if index exists\n",
    "HNSW_INDEX_NAME = INDEX_NAME+ \"_HNSW\"\n",
    "\n",
    "try:\n",
    "    redis_client.ft(HNSW_INDEX_NAME).info()\n",
    "    print(\"Index already exists\")\n",
    "except:\n",
    "    # Create RediSearch Index\n",
    "    redis_client.ft(HNSW_INDEX_NAME).create_index(\n",
    "        fields = fields,\n",
    "        definition = IndexDefinition(prefix=[PREFIX], index_type=IndexType.HASH)\n",
    "    )\n",
    "\n",
    "# since RediSearch creates the index in the background for existing documents, we will wait until\n",
    "# indexing is complete before running our queries. Although this is not necessary for the first query,\n",
    "# some queries may take longer to run if the index is not fully built. In general, Redis will perform\n",
    "# best when adding new documents to existing indices rather than new indices on existing documents.\n",
    "while redis_client.ft(HNSW_INDEX_NAME).info()[\"indexing\"] == \"1\":\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8e474447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6360332  0.94766825 0.9268919  ... 0.25700685 0.3106769  0.40567252]\n",
      "0. Derby County F.C. (Score: 0.008)\n",
      "1. Roller derby (Score: -0.001)\n",
      "2. Derby (Score: -0.002)\n",
      "3. Derbyshire (Score: -0.003)\n",
      "4. River Adur (Score: -0.003)\n",
      "5. Robert Dyas (Score: -0.003)\n",
      "6. Las Vegas Raiders (Score: -0.004)\n",
      "7. Riviera (district) (Score: -0.004)\n",
      "8. Leeds (Score: -0.004)\n",
      "9. Derby (disambiguation) (Score: -0.005)\n"
     ]
    }
   ],
   "source": [
    "arr = np.random.rand(VECTOR_DIM).astype(np.float32)\n",
    "\n",
    "results = search_redis(redis_client, arr, index_name=HNSW_INDEX_NAME, k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cb799e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare the results of the HNSW index to the FLAT index and time both queries\n",
    "def time_queries(iterations: int = 10):\n",
    "    print(\" ----- Flat Index ----- \")\n",
    "    t0 = time.time()\n",
    "\n",
    "    for i in range(iterations):\n",
    "        arr = np.random.rand(VECTOR_DIM).astype(np.float32)\n",
    "        results_flat = search_redis(redis_client, arr, k=10, print_results=False)\n",
    "    t0 = (time.time() - t0) / iterations\n",
    "\n",
    "    arr = np.random.rand(VECTOR_DIM).astype(np.float32)\n",
    "    results_flat = search_redis(redis_client, arr, k=10, print_results=True)\n",
    "    print(f\"Flat index query time: {round(t0, 3)} seconds\\n\")\n",
    "\n",
    "    time.sleep(1)\n",
    "    print(\" ----- HNSW Index ------ \")\n",
    "    t1 = time.time()\n",
    "    for i in range(iterations):\n",
    "        arr = np.random.rand(VECTOR_DIM).astype(np.float32)\n",
    "        results_hnsw = search_redis(redis_client, arr, index_name=HNSW_INDEX_NAME, k=10, print_results=False)\n",
    "    t1 = (time.time() - t1) / iterations\n",
    "    arr = np.random.rand(VECTOR_DIM).astype(np.float32)\n",
    "    results_hnsw = search_redis(redis_client, arr, index_name=HNSW_INDEX_NAME, k=10, print_results=True)\n",
    "    print(f\"HNSW index query time: {round(t1, 3)} seconds\")\n",
    "    print(\" ------------------------ \")\n",
    "# time_queries()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "69aa7a09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ----- Flat Index ----- \n",
      "0. Aerial root (Score: -0.004)\n",
      "1. Stem (music) (Score: -0.008)\n",
      "2. Meter (poetry) (Score: -0.009)\n",
      "3. Pupil (eye) (Score: -0.01)\n",
      "4. Chloroplast (Score: -0.01)\n",
      "5. Vertebra (Score: -0.01)\n",
      "6. Phrasal verb (Score: -0.01)\n",
      "7. Phototroph (Score: -0.011)\n",
      "8. Nth root (Score: -0.011)\n",
      "9. If (Beyoncé song) (Score: -0.011)\n",
      "Flat index query time: 0.011 seconds\n",
      "\n",
      " ----- HNSW Index ------ \n",
      "0. Kingdom Hearts II (Score: -0.023)\n",
      "1. Mickey Mouse (Score: -0.023)\n",
      "2. Scream 2 (Score: -0.024)\n",
      "3. Daffy Duck (Score: -0.024)\n",
      "4. Toy Story 2 (Score: -0.024)\n",
      "5. Pumpkin Studios (Score: -0.024)\n",
      "6. PlayStation 2 (Score: -0.025)\n",
      "7. George Lucas (Score: -0.025)\n",
      "8. Guitar Hero II (Score: -0.025)\n",
      "9. Tekken 2 (Score: -0.026)\n",
      "HNSW index query time: 0.001 seconds\n",
      " ------------------------ \n"
     ]
    }
   ],
   "source": [
    "time_queries()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "redisvl2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "9b1e6e9c2967143209c2f955cb869d1d3234f92dc4787f49f155f3abbdfb1316"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
