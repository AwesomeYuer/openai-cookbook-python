{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Qdrant as a vector database for OpenAI embeddings\n",
    "\n",
    "This notebook guides you step by step on using **`Qdrant`** as a vector database for OpenAI embeddings. [Qdrant](https://qdrant.tech) is a high-performant vector search database written in Rust. It offers RESTful and gRPC APIs to manage your embeddings. There is an official Python [qdrant-client](https://github.com/qdrant/qdrant_client) that eases the integration with your apps.\n",
    "\n",
    "This notebook presents an end-to-end process of:\n",
    "1. Using precomputed embeddings created by OpenAI API.\n",
    "2. Storing the embeddings in a local instance of Qdrant.\n",
    "3. Converting raw text query to an embedding with OpenAI API.\n",
    "4. Using Qdrant to perform the nearest neighbour search in the created collection.\n",
    "\n",
    "### What is Qdrant\n",
    "\n",
    "[Qdrant](https://qdrant.tech) is an Open Source vector database that allows storing neural embeddings along with the metadata, a.k.a [payload](https://qdrant.tech/documentation/payload/). Payloads are not only available for keeping some additional attributes of a particular point, but might be also used for filtering. [Qdrant](https://qdrant.tech) offers a unique filtering mechanism which is built-in into the vector search phase, what makes it really efficient.\n",
    "\n",
    "### Deployment options\n",
    "\n",
    "[Qdrant](https://qdrant.tech) might be launched in various ways, depending on the target load on the application it might be hosted:\n",
    "\n",
    "- Locally or on premise, with Docker containers\n",
    "- On Kubernetes cluster, with the [Helm chart](https://github.com/qdrant/qdrant-helm)\n",
    "- Using [Qdrant Cloud](https://cloud.qdrant.io/)\n",
    "\n",
    "### Integration\n",
    "\n",
    "[Qdrant](https://qdrant.tech) provides both RESTful and gRPC APIs which makes integration easy, no matter the programming language you use. However, there are some official clients for the most popular languages available, and if you use Python then the [Python Qdrant client library](https://github.com/qdrant/qdrant_client) might be the best choice."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "For the purposes of this exercise we need to prepare a couple of things:\n",
    "\n",
    "1. Qdrant server instance. In our case a local Docker container.\n",
    "2. The [qdrant-client](https://github.com/qdrant/qdrant_client) library to interact with the vector database.\n",
    "\n",
    "### Start Qdrant server\n",
    "\n",
    "We're going to use a local Qdrant instance running in a Docker container. The easiest way to launch it is to use the attached [docker-compose.yaml] file and run the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-16T12:04:28.198036Z",
     "start_time": "2023-02-16T12:04:26.950014Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qdrant_qdrant_1 is up-to-date\r\n"
     ]
    }
   ],
   "source": [
    "! docker-compose up -d\n",
    "\n",
    "! sudo docker run -d -p 6333:6333 -p 6334:6334 --name qdrant -v /userdata/temp:/share qdrant/qdrant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We might validate if the server was launched successfully by running a simple curl command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-16T12:04:29.301651Z",
     "start_time": "2023-02-16T12:04:29.173153Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"title\":\"qdrant - vector search engine\",\"version\":\"1.1.2\"}"
     ]
    }
   ],
   "source": [
    "! curl http://localhost:6333"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install requirements\n",
    "\n",
    "This notebook obviously requires the `openai` and `qdrant-client` packages, but there are also some other additional libraries we will use. The following command installs them all:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-16T12:05:05.718972Z",
     "start_time": "2023-02-16T12:04:30.434820Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Downloading openai-0.27.6-py3-none-any.whl (71 kB)\n",
      "\u001b[K     |████████████████████████████████| 71 kB 324 kB/s eta 0:00:011\n",
      "\u001b[?25hCollecting qdrant-client\n",
      "  Downloading qdrant_client-1.1.6-py3-none-any.whl (126 kB)\n",
      "\u001b[K     |████████████████████████████████| 126 kB 6.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pandas\n",
      "  Downloading pandas-2.0.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 12.3 MB 46.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting wget\n",
      "  Downloading wget-3.2.zip (10 kB)\n",
      "Collecting aiohttp\n",
      "  Downloading aiohttp-3.8.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.0 MB 87.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/lib/python3/dist-packages (from openai) (2.22.0)\n",
      "Collecting tqdm\n",
      "  Downloading tqdm-4.65.0-py3-none-any.whl (77 kB)\n",
      "\u001b[K     |████████████████████████████████| 77 kB 6.7 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting numpy>=1.21; python_version >= \"3.8\"\n",
      "  Downloading numpy-1.24.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 17.3 MB 82.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions<5.0.0,>=4.0.0 in /home/AwesomeYuer/.local/lib/python3.8/site-packages (from qdrant-client) (4.5.0)\n",
      "Collecting grpcio>=1.41.0\n",
      "  Downloading grpcio-1.54.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 5.1 MB 76.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pydantic<2.0,>=1.8\n",
      "  Downloading pydantic-1.10.7-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.2 MB 80.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting grpcio-tools>=1.41.0\n",
      "  Downloading grpcio_tools-1.54.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.4 MB 72.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting urllib3<2.0.0,>=1.26.14\n",
      "  Downloading urllib3-1.26.15-py2.py3-none-any.whl (140 kB)\n",
      "\u001b[K     |████████████████████████████████| 140 kB 81.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting httpx[http2]>=0.14.0\n",
      "  Downloading httpx-0.24.0-py3-none-any.whl (75 kB)\n",
      "\u001b[K     |████████████████████████████████| 75 kB 3.0 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting tzdata>=2022.1\n",
      "  Downloading tzdata-2023.3-py2.py3-none-any.whl (341 kB)\n",
      "\u001b[K     |████████████████████████████████| 341 kB 94.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /home/AwesomeYuer/.local/lib/python3.8/site-packages (from pandas) (2.8.2)\n",
      "Collecting pytz>=2020.1\n",
      "  Downloading pytz-2023.3-py2.py3-none-any.whl (502 kB)\n",
      "\u001b[K     |████████████████████████████████| 502 kB 96.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/lib/python3/dist-packages (from aiohttp->openai) (19.3.0)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.3.3-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (161 kB)\n",
      "\u001b[K     |████████████████████████████████| 161 kB 95.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting charset-normalizer<4.0,>=2.0\n",
      "  Downloading charset_normalizer-3.1.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (195 kB)\n",
      "\u001b[K     |████████████████████████████████| 195 kB 73.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n",
      "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.9.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (266 kB)\n",
      "\u001b[K     |████████████████████████████████| 266 kB 84.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-6.0.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (121 kB)\n",
      "\u001b[K     |████████████████████████████████| 121 kB 84.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting aiosignal>=1.1.2\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from grpcio-tools>=1.41.0->qdrant-client) (45.2.0)\n",
      "Collecting protobuf<5.0dev,>=4.21.6\n",
      "  Downloading protobuf-4.22.3-cp37-abi3-manylinux2014_x86_64.whl (302 kB)\n",
      "\u001b[K     |████████████████████████████████| 302 kB 104.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting httpcore<0.18.0,>=0.15.0\n",
      "  Downloading httpcore-0.17.0-py3-none-any.whl (70 kB)\n",
      "\u001b[K     |████████████████████████████████| 70 kB 10.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: certifi in /usr/lib/python3/dist-packages (from httpx[http2]>=0.14.0->qdrant-client) (2019.11.28)\n",
      "Requirement already satisfied: idna in /usr/lib/python3/dist-packages (from httpx[http2]>=0.14.0->qdrant-client) (2.8)\n",
      "Collecting sniffio\n",
      "  Downloading sniffio-1.3.0-py3-none-any.whl (10 kB)\n",
      "Collecting h2<5,>=3; extra == \"http2\"\n",
      "  Downloading h2-4.1.0-py3-none-any.whl (57 kB)\n",
      "\u001b[K     |████████████████████████████████| 57 kB 5.7 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas) (1.14.0)\n",
      "Collecting anyio<5.0,>=3.0\n",
      "  Downloading anyio-3.6.2-py3-none-any.whl (80 kB)\n",
      "\u001b[K     |████████████████████████████████| 80 kB 11.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting h11<0.15,>=0.13\n",
      "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "\u001b[K     |████████████████████████████████| 58 kB 8.8 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting hpack<5,>=4.0\n",
      "  Downloading hpack-4.0.0-py3-none-any.whl (32 kB)\n",
      "Collecting hyperframe<7,>=6.0\n",
      "  Downloading hyperframe-6.0.1-py3-none-any.whl (12 kB)\n",
      "Building wheels for collected packages: wget\n",
      "  Building wheel for wget (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9681 sha256=11dc3e6fca394d7fa2727938c9e150e75593f9c84cb69ee56dce97e943545c3e\n",
      "  Stored in directory: /home/AwesomeYuer/.cache/pip/wheels/bd/a8/c3/3cf2c14a1837a4e04bd98631724e81f33f462d86a1d895fae0\n",
      "Successfully built wget\n",
      "Installing collected packages: frozenlist, charset-normalizer, async-timeout, multidict, yarl, aiosignal, aiohttp, tqdm, openai, numpy, grpcio, pydantic, protobuf, grpcio-tools, urllib3, sniffio, anyio, h11, httpcore, hpack, hyperframe, h2, httpx, qdrant-client, tzdata, pytz, pandas, wget\n",
      "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 anyio-3.6.2 async-timeout-4.0.2 charset-normalizer-3.1.0 frozenlist-1.3.3 grpcio-1.54.0 grpcio-tools-1.54.0 h11-0.14.0 h2-4.1.0 hpack-4.0.0 httpcore-0.17.0 httpx-0.24.0 hyperframe-6.0.1 multidict-6.0.4 numpy-1.24.3 openai-0.27.6 pandas-2.0.1 protobuf-4.22.3 pydantic-1.10.7 pytz-2023.3 qdrant-client-1.1.6 sniffio-1.3.0 tqdm-4.65.0 tzdata-2023.3 urllib3-1.26.15 wget-3.2 yarl-1.9.2\n"
     ]
    }
   ],
   "source": [
    "! pip install qdrant-client pandas wget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to Qdrant\n",
    "\n",
    "Connecting to a running instance of Qdrant server is easy with the official Python library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-16T12:05:06.827143Z",
     "start_time": "2023-02-16T12:05:05.733771Z"
    }
   },
   "outputs": [],
   "source": [
    "import qdrant_client\n",
    "\n",
    "client = qdrant_client.QdrantClient(\n",
    "    host=\"localhost\",\n",
    "    prefer_grpc=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can test the connection by running any available method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-16T12:05:06.848488Z",
     "start_time": "2023-02-16T12:05:06.832612Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CollectionsResponse(collections=[])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.get_collections()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n",
    "\n",
    "In this section we are going to load the data prepared previous to this session, so you don't have to recompute the embeddings of Wikipedia articles with your own credits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can finally load it from the provided CSV file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-16T12:17:35.483972Z",
     "start_time": "2023-02-16T12:06:01.540172Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>title_vector</th>\n",
       "      <th>content_vector</th>\n",
       "      <th>vector_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>https://simple.wikipedia.org/wiki/April</td>\n",
       "      <td>April</td>\n",
       "      <td>April is the fourth month of the year in the J...</td>\n",
       "      <td>[0.001009464613161981, -0.020700545981526375, ...</td>\n",
       "      <td>[-0.011253940872848034, -0.013491976074874401,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>https://simple.wikipedia.org/wiki/August</td>\n",
       "      <td>August</td>\n",
       "      <td>August (Aug.) is the eighth month of the year ...</td>\n",
       "      <td>[0.0009286514250561595, 0.000820168002974242, ...</td>\n",
       "      <td>[0.0003609954728744924, 0.007262262050062418, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>https://simple.wikipedia.org/wiki/Art</td>\n",
       "      <td>Art</td>\n",
       "      <td>Art is a creative activity that expresses imag...</td>\n",
       "      <td>[0.003393713850528002, 0.0061537534929811954, ...</td>\n",
       "      <td>[-0.004959689453244209, 0.015772193670272827, ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>https://simple.wikipedia.org/wiki/A</td>\n",
       "      <td>A</td>\n",
       "      <td>A or a is the first letter of the English alph...</td>\n",
       "      <td>[0.0153952119871974, -0.013759135268628597, 0....</td>\n",
       "      <td>[0.024894846603274345, -0.022186409682035446, ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>https://simple.wikipedia.org/wiki/Air</td>\n",
       "      <td>Air</td>\n",
       "      <td>Air refers to the Earth's atmosphere. Air is a...</td>\n",
       "      <td>[0.02224554680287838, -0.02044147066771984, -0...</td>\n",
       "      <td>[0.021524671465158463, 0.018522677943110466, -...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                       url   title   \n",
       "0   1   https://simple.wikipedia.org/wiki/April   April  \\\n",
       "1   2  https://simple.wikipedia.org/wiki/August  August   \n",
       "2   6     https://simple.wikipedia.org/wiki/Art     Art   \n",
       "3   8       https://simple.wikipedia.org/wiki/A       A   \n",
       "4   9     https://simple.wikipedia.org/wiki/Air     Air   \n",
       "\n",
       "                                                text   \n",
       "0  April is the fourth month of the year in the J...  \\\n",
       "1  August (Aug.) is the eighth month of the year ...   \n",
       "2  Art is a creative activity that expresses imag...   \n",
       "3  A or a is the first letter of the English alph...   \n",
       "4  Air refers to the Earth's atmosphere. Air is a...   \n",
       "\n",
       "                                        title_vector   \n",
       "0  [0.001009464613161981, -0.020700545981526375, ...  \\\n",
       "1  [0.0009286514250561595, 0.000820168002974242, ...   \n",
       "2  [0.003393713850528002, 0.0061537534929811954, ...   \n",
       "3  [0.0153952119871974, -0.013759135268628597, 0....   \n",
       "4  [0.02224554680287838, -0.02044147066771984, -0...   \n",
       "\n",
       "                                      content_vector  vector_id  \n",
       "0  [-0.011253940872848034, -0.013491976074874401,...          0  \n",
       "1  [0.0003609954728744924, 0.007262262050062418, ...          1  \n",
       "2  [-0.004959689453244209, 0.015772193670272827, ...          2  \n",
       "3  [0.024894846603274345, -0.022186409682035446, ...          3  \n",
       "4  [0.021524671465158463, 0.018522677943110466, -...          4  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from ast import literal_eval\n",
    "\n",
    "article_df = pd.read_csv('../../data/vector_database_wikipedia_articles_embedded.csv')\n",
    "# Read vectors from strings back into a list\n",
    "article_df[\"title_vector\"] = article_df.title_vector.apply(literal_eval)\n",
    "article_df[\"content_vector\"] = article_df.content_vector.apply(literal_eval)\n",
    "article_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index data\n",
    "\n",
    "Qdrant stores data in __collections__ where each object is described by at least one vector and may contain an additional metadata called __payload__. Our collection will be called **Articles** and each object will be described by both **title** and **content** vectors. Qdrant does not require you to set up any kind of schema beforehand, so you can freely put points to the collection with a simple setup only.\n",
    "\n",
    "We will start with creating a collection, and then we will fill it with our precomputed embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-16T12:17:36.366066Z",
     "start_time": "2023-02-16T12:17:35.486872Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from qdrant_client.http import models as rest\n",
    "\n",
    "vector_size = len(article_df[\"content_vector\"][0])\n",
    "\n",
    "client.recreate_collection(\n",
    "    collection_name=\"Articles\",\n",
    "    vectors_config={\n",
    "        \"title\": rest.VectorParams(\n",
    "            distance=rest.Distance.COSINE,\n",
    "            size=vector_size,\n",
    "        ),\n",
    "        \"content\": rest.VectorParams(\n",
    "            distance=rest.Distance.COSINE,\n",
    "            size=vector_size,\n",
    "        ),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-16T12:30:37.518210Z",
     "start_time": "2023-02-16T12:17:36.368564Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UpdateResult(operation_id=0, status=<UpdateStatus.COMPLETED: 'completed'>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.upsert(\n",
    "    collection_name=\"Articles\",\n",
    "    points=[\n",
    "        rest.PointStruct(\n",
    "            id=k,\n",
    "            vector={\n",
    "                \"title\": v[\"title_vector\"],\n",
    "                \"content\": v[\"content_vector\"],\n",
    "            },\n",
    "            payload=v.to_dict(),\n",
    "        )\n",
    "        for k, v in article_df.iterrows()\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-16T12:30:40.675202Z",
     "start_time": "2023-02-16T12:30:40.655654Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountResult(count=25000)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the collection size to make sure all the points have been stored\n",
    "client.count(collection_name=\"Articles\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search data\n",
    "\n",
    "Once the data is put into Qdrant we will start querying the collection for the closest vectors. We may provide an additional parameter `vector_name` to switch from title to content based search. Since the precomputed embeddings were created with `text-embedding-ada-002` OpenAI model we also have to use it during search.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-16T12:30:38.024370Z",
     "start_time": "2023-02-16T12:30:37.712816Z"
    }
   },
   "outputs": [],
   "source": [
    "# import openai\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def query_qdrant(query, collection_name, vector_name=\"title\", top_k=20):\n",
    "    # Creates embedding vector from user query\n",
    "    # embedded_query = openai.Embedding.create(\n",
    "    #     input=query,\n",
    "    #     model=\"text-embedding-ada-002\",\n",
    "    # )[\"data\"][0][\"embedding\"]\n",
    "\n",
    "    # 生成随机浮点数数组\n",
    "    arr = np.random.rand(1536).astype(np.float32)\n",
    "\n",
    "\n",
    "    query_results = client.search(\n",
    "        collection_name=collection_name,\n",
    "        query_vector=(\n",
    "            vector_name,  arr #embedded_query\n",
    "        ),\n",
    "        limit=top_k,\n",
    "    )\n",
    "\n",
    "    return query_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-16T12:30:39.379566Z",
     "start_time": "2023-02-16T12:30:38.031041Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. List of emotions (Score: 0.002)\n",
      "2. Ratchet & Clank (2002 video game) (Score: 0.002)\n",
      "3. National Football League (Score: 0.002)\n",
      "4. New England Patriots (Score: 0.001)\n",
      "5. Richard Childress Racing (Score: 0.001)\n",
      "6. World Heavyweight Championship (WWE) (Score: 0.001)\n",
      "7. List of water sports (Score: 0.001)\n",
      "8. Bill Watterson (Score: -0.0)\n",
      "9. Tachycardia (Score: -0.0)\n",
      "10. Newton's laws of motion (Score: -0.001)\n",
      "11. Beat 'em up games (Score: -0.001)\n",
      "12. Blue Balliett (Score: -0.001)\n",
      "13. Speed (1994 movie) (Score: -0.001)\n",
      "14. Crash Bandicoot (series) (Score: -0.001)\n",
      "15. Resting potential (Score: -0.001)\n",
      "16. Hank Ballard (Score: -0.001)\n",
      "17. Heart disease (Score: -0.002)\n",
      "18. Ratchet & Clank (series) (Score: -0.002)\n",
      "19. Hyperthyroidism (Score: -0.002)\n",
      "20. Blood pressure (Score: -0.002)\n"
     ]
    }
   ],
   "source": [
    "query_results = query_qdrant(\"modern art in Europe\", \"Articles\")\n",
    "for i, article in enumerate(query_results):\n",
    "    print(f\"{i + 1}. {article.payload['title']} (Score: {round(article.score, 3)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-16T12:30:40.652676Z",
     "start_time": "2023-02-16T12:30:39.382555Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Svecchachara (Score: 0.005)\n",
      "2. Shahada (Score: 0.002)\n",
      "3. Code (Score: 0.001)\n",
      "4. Chrysler Building (Score: 0.001)\n",
      "5. Tor (disambiguation) (Score: 0.001)\n",
      "6. Suez Canal (Score: -0.0)\n",
      "7. Filter (internet) (Score: -0.0)\n",
      "8. Names of God in Judaism (Score: -0.001)\n",
      "9. Arctic Circle (Score: -0.001)\n",
      "10. 900 North Michigan (Score: -0.001)\n",
      "11. List of tallest structures in the world (Score: -0.002)\n",
      "12. Park Tower (Score: -0.002)\n",
      "13. NATO phonetic alphabet (Score: -0.002)\n",
      "14. Soapbox (Score: -0.002)\n",
      "15. Torre (Score: -0.002)\n",
      "16. Parallel (Score: -0.002)\n",
      "17. Acronym (Score: -0.002)\n",
      "18. YHWH (Score: -0.003)\n",
      "19. Political correctness (Score: -0.003)\n",
      "20. Code (disambiguation) (Score: -0.003)\n"
     ]
    }
   ],
   "source": [
    "# This time we'll query using content vector\n",
    "query_results = query_qdrant(\"Famous battles in Scottish history\", \"Articles\", \"content\")\n",
    "for i, article in enumerate(query_results):\n",
    "    print(f\"{i + 1}. {article.payload['title']} (Score: {round(article.score, 3)})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
